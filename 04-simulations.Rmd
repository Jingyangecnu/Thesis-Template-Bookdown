# 数值模拟 {#simulations}

空间广义线性混合效应模型在广义线性混合效应模型基础上添加了与空间位置相关的随机效应，这种随机效应在文献中常称为空间效应 [@Diggle1998]。 它与采样点的位置、数量都有关系， 其中采样点的位置决定空间过程的协方差结构， 而采样点的数量决定空间效应的维度，从而导致空间广义线性混合效应模型比普通的广义线性混合效应模型复杂。作为过渡，我们在第 \@ref(sim-one-gp) 和 \@ref(sim-two-gp) 节模拟了一维和二维平稳高斯过程。 第 \@ref(sim-sglmm) 节模拟 SGLMM 模型， 分两个小节展开叙述，第 \@ref(sim-binomal-sglmm) 小节模拟响应变量服从二项分布的情形，  第 \@ref(possion-sglmm) 小节模拟响应变量服从泊松分布的情形，在这两个小节里， 比较了蒙特卡罗极大似然算法，低秩近似算法，贝叶斯马尔科夫链蒙特卡罗算法和贝叶斯 STAN-MCMC 算法的性能差异。

模拟空间广义线性混合效应模型 \@ref(eq:sim-sglmm) 分三节进行，第一节模拟空间高斯过程 $S(x)$，第二节模拟响应变量 $Y$ 服从二项分布 ，第三节模拟响应变量 $Y$ 服从正态分布。空间高斯过程在模型 \@ref(eq:sim-sglmm) 中作为随机效应存在，不同于一般随机效应的地方在于它与样本的空间位置有关，一般地，假定 $S(x)$ 服从 $N$ 元高斯分布 $N(\mu_{S},G)$，$x = (d_1,d_2) \in \mathbb{R}^2$， $\mu_{S} = \mathbf{0}_{N\times1}$， $G_{(ij)} = \mathrm{Cov}(S(x_i),S(x_j))=\sigma^2*\rho(u_{ij})$， $S(x)$ 的相关函数 $\rho(u_{ij}) = \exp(-u_{ij}/\phi), u_{ij} \equiv \|x_{i}-x_{j}\|_2$，其中 $\phi$ 和 $\sigma^2$ 都是未知待估参数。可见采样点的位置 $(d_1,d_2)$ 和相关函数 $\rho(u)$ 一起决定空间高斯过程的形式，并且 $S(x)$ 的维度就是采样点的数目 $N$。这样通常导致空间效应的维度比协变量的数目大很多，模型 \@ref(eq:sim-sglmm) 的估计问题也比一般的广义线性混合效应模型困难。

\begin{equation}
g(\mu_i) = d(x_i)'\beta + S(x_i) + Z_i (\#eq:sim-sglmm)
\end{equation}

## 平稳空间高斯过程 {#spatial-gaussian-processes}

### 一维平稳空间高斯过程 {#sim-one-gp}

一维情形下，平稳高斯过程 $S(x)$ 的协方差函数采用幂指数型，见公式 \@ref(eq:cov-exp-quad)，当 $\kappa =1$ 时，为指数型，见公式 \@ref(eq:cov-exp-quad)。分 $\kappa =1$ 和 $\kappa =1$，模拟两个一维平稳空间高斯过程，协方差参数均为 $\sigma^2 = 1$，$\phi = 0.15$，均值向量都是 $\mathbf{0}$，在 $[-2,2]$ 的区间上，产生 2000 个服从均匀分布的随机数，由这些随机数的未知和协方差函数公式 \@ref(eq:cov-exp) 或 \@ref(eq:cov-exp-quad) 计算得到 2000 维的高斯分布的协方差矩阵 $G$，为保证协方差矩阵的正定性，在矩阵对角线上添加扰动 $1 \times 10^{-12}$，然后即可根据 Cholesky 分解该对称正定矩阵，得到下三角块 $L$，使得 $G = L \times L^{\top}$，再产生 2000 个服从标准正态分布的随机向量 $\eta$，而 $L\eta$ 即为所需的服从平稳高斯过程的一组随机数。

\begin{align}
\mathsf{Cov}(S(x_i), S(x_j)) & = \sigma^2 \exp\big\{ - \frac{|x_{i} - x_{j}|}{ \phi } \big\}  (\#eq:cov-exp) \\
\mathsf{Cov}(S(x_i), S(x_j)) & = \sigma^2 \exp\big\{ -\big( \frac{ |x_{i} - x_{j}| }{ \phi } \big) ^ {\kappa} \big\}, 0 < \kappa \leq 2  (\#eq:cov-exp-quad) 
\end{align}

```{r sim-one-gp, eval=FALSE, echo=FALSE}
# 指数型协方差函数
sim_one_gp_model_exp <- stan_model("code/sim_one_gp_exp.stan")
# 幂二次指数型协方差函数
sim_one_gp_model_exp_quad <- stan_model("code/sim_one_gp_exp_quad.stan")

dat_list <- list(N = 2000, sigma = 1, phi = 0.15)
set <- sample(1:dat_list$N, size = 36, replace = F) # 部分数据集

draw <- sampling(sim_one_gp_model_exp,
  iter = 1, algorithm = "Fixed_param",
  chains = 1, data = dat_list,
  seed = 363360090
)

draw <- sampling(sim_one_gp_model_exp_quad,
  iter = 1, algorithm = "Fixed_param",
  chains = 1, data = dat_list,
  seed = 363360090
)

samps <- rstan::extract(draw)
plt_df <- with(samps, data.frame(x = x[1, ], f = f[1, ]))
```
```{r one-dim-gp,fig.cap='(ref:one-dim-gp)',fig.ncol=1,fig.sep="\\\\",fig.subcap=c("平稳空间高斯过程 $S(x)$ 的协方差函数是指数型，均值向量为 $\\mathbf{0}$，协方差参数 $\\sigma^2 = 1$，$\\phi = 0.15$","平稳空间高斯过程 $S(x)$ 的协方差函数是幂二次指数型，均值向量为 $\\mathbf{0}$，协方差参数 $\\sigma^2 = 1$，$\\phi = 0.15$，$\\kappa=2$")}
# 指数型协方差函数  连续但是在原点不可微
# pdf(file = "one-dim-gp-exp.pdf", width = 8, height = 8 * 0.618)
# par(mar = c(4.1, 4.1, 1.5, 0.5))
# plot(f ~ x, data = plt_df, xlab = "x", ylab = "S(x)",pch = 16,col  = "Darkgrey")
# points(f~x,data = plt_df[set,], pch = 16, col = 'darkorange')
# dev.off()
# 幂二次指数型协方差函数 不但连续而且无穷可微
# pdf(file = "one-dim-gp-exp-quad.pdf", width = 8, height = 8 * 0.618)
# par(mar = c(4.1, 4.1, 1.5, 0.5))
# plot(f ~ x, data = plt_df, xlab = "x", ylab = "S(x)",pch = 16,col  = "Darkgrey")
# points(f~x,data = plt_df[set,], pch = 16, col = 'darkorange')
# dev.off()

knitr::include_graphics(path = c(
  "figures/one-dim-gp-exp.png",
  "figures/one-dim-gp-exp-quad.png"
))
```

(ref:one-dim-gp) 模拟一维平稳空间高斯过程，协方差函数分别为指数型 \@ref(eq:cov-exp) 和幂二次指数型 \@ref(eq:cov-exp-quad)，均值为 $\mathbf{0}$，协方差参数 $\sigma^2 = 1$，$\phi = 0.15$，横坐标表示采样的位置，纵坐标是目标值 $S(x)$，图中 2000 个灰色点表示服从相应随机过程的随机数，橘黄色点是从中随机选择的 36 个点。

根据定理 \@ref(thm:stationary-mean-square-properties)，指数型协方差函数的平稳高斯过程在原点连续但是不可微，而幂二次指数型协方差函数在原点无穷可微，可微性越好图像上表现越光滑，对比图 \@ref(fig:one-dim-gp) 的两个子图， 可以看出，在协方差参数 $\sigma^2 = 1$，$\phi = 0.15$ 相同的情况下，$\kappa$ 越大越光滑。

### 二维平稳空间高斯过程 {#sim-two-gp}

二维情形下，在规则平面上模拟平稳高斯过程 $\mathcal{S} = S(x), x \in \mathbb{R}^2$， 其均值向量为零向量 $\mathbf{0}$， 协方差函数为指数型 (见公式 \@ref(eq:cov-exp)) ，协方差参数 $\phi = 1, \sigma^2 = 1$。在单位平面区域为 $[0,1] \times [0,1]$ 模拟服从上述二维空间平稳高斯过程，不妨将此区域划分为 $6 \times 6$ 的小网格，而每个格点作为采样的位置，共计 36个采样点，在这些采样点上的观察值即为目标值 $S(x)$。 

类似本章第 \@ref(sim-one-gp) 节模拟一维平稳空间过程的步骤， 首先根据采样点位置坐标和协方差函数 \@ref(eq:cov-exp-quad) 计算得目标空间过程的 $\mathcal{S}$ 协方差矩阵 $G$，然后使用 R 包 **MASS** 提供的 `mvrnorm` 函数产生多元正态分布随机数，与 \@ref(sim-one-gp) 节不同的是这里采用特征值分解，即 $G = L\Lambda L^{\top}$，与 Cholesky 分解相比，特征值分解更稳定些，但是 Cholesky 分解更快，Stan 即采用此法，后续过程与一维模拟一致。模拟获得的随机数用图 \@ref(fig:sim-two-gp) 表示， 格点上的值即为平稳空间高斯过程在该点的取值 (为方便显示，已四舍五入保留两位小数)。

```{r sim-two-gp,fig.cap="模拟二维平稳空间高斯过程，自相关函数为指数形式，水平方向为横坐标，垂直方向为纵坐标，图中的橘黄色点是采样的位置，其上的数字是目标值 $S(x)$",fig.subcap=c("在单位区域的网格点上采样","在单位区域上随机采样"), small.mar=TRUE,out.width="45%",fig.show='hold',fig.asp=1,fig.width=4.5}
set.seed(2018)
N <- 36
phi <- 1
sigma <- 1
## 单位区域上采样
d <- expand.grid(
  d1 = seq(0, 1, l = sqrt(N)),
  d2 = seq(0, 1, l = sqrt(N))
)
D <- as.matrix(dist(d)) # 计算采样点之间的欧氏距离
G <- sigma^2 * exp(- D / phi) # 多元高斯分布的协方差矩阵
S <- MASS::mvrnorm(1, rep(0, N), G) # 产生服从多元高斯分布的随机数
plot(c(-0.1, 1.1), c(-0.1, 1.1),
  type = "n",
  panel.first = grid(lwd = 1.5, lty = 2, col = "lightgray"),
  xlab = "Horizontal Coordinate", ylab = "Vertical Coordinate"
)
# text(y = d$d1, x = d$d2, labels = round(S, digits = 2), xpd = TRUE)
points(y = d$d1, x = d$d2, pch = 16, col = "darkorange")
text(
  y = d$d1, x = d$d2,
  labels = formatC(round(S, digits = 2), format = "f", 
                   digits = 2, drop0trailing = FALSE), 
  xpd = TRUE
)
# 在单位区域上随机采样
set.seed(2018)
n <- 36
coords <- cbind.data.frame(d1 = runif(n, 0, 1), d2 = runif(n, 0, 1))
phi <- 1
sigma <- 1
R <- exp(- as.matrix(dist(coords)) / phi)
S <- MASS::mvrnorm(1, rep(0, n), sigma * R)

plot(c(-0.1, 1.1), c(-0.1, 1.1),
  type = "n",
  xlab = "Horizontal Coordinate", ylab = "Vertical Coordinate"
)
points(y = coords$d1, x = coords$d2, pch = 16, col = "darkorange")
text(
  y = coords$d1, x = coords$d2,
  labels = formatC(round(S, digits = 2), format = "f",
                   digits = 2, drop0trailing = FALSE),
  xpd = TRUE
)
```
```{r with-nugget,eval=FALSE,include=FALSE}
# nugget = tau^2 # nugget effect
# cov.pars = c(sigma^2,phi) # partial sill and range parameter
library(geoR)
sim <- grf(36,
  grid = "reg", method = "cholesky",
  cov.pars = c(1, sqrt(2)), nugget = 1, mean = 0,
  cov.model = "powered.exponential", kappa = 2
)
# a display of simulated locations and values
plot(sim$coords, type = "n")
text(sim$coords[, 1], sim$coords[, 2], format(sim$data, digits = 1), cex = 1.5)
```

同 \@ref(sim-one-gp) 节，二维平稳空间高斯过程 $S(x)$ 的协方差函数也可以为更一般的梅隆型，如公式 \@ref(eq:exp-matern) 所示。

\begin{equation}
\rho(u) = \sigma^2 \{ 2^{\kappa -1} \Gamma(\kappa) \}^{-1}( u/\phi )^{\kappa} \mathcal{K}_{\kappa}( u / \phi ) (\#eq:exp-matern)
\end{equation}

\noindent 且在区域 $[0,1] \times [0,1]$ 上也可以随机采点，如图 \@ref(fig:sim-two-gp) 的右子图所示。

模拟平稳空间高斯过程的其它 R 包实现方法： Paulo J. Ribeiro Jr. 和 Peter J. Diggle 开发了 **geoR** 包 [@geoR2001]，提供的 `grf` 函数除了实现 Cholesky 分解，还实现了奇异值分解，特征值分解协方差矩阵的算法。当采样点不太多时，Cholesky 分解已经足够好，下面的第 \@ref(sim-sglmm) 节对平稳空间高斯过程的数值模拟即采用此法，当采样点很多，为了加快模拟的速度，可以选用 Martin Schlather 等开发的 **RandomFields** 包 [@RandomFields2015]，内置的 `GaussRF` 函数实现了用高斯马尔科夫随机场近似平稳空间高斯过程的算法，此外，Håvard Rue 等 (2009年) [@Rue2009] 也实现了从平稳高斯过程到高斯马尔科夫随机场的近似算法，开发了更为高效的 INLA 程序库 [@INLA2015]，其内置的近似程序得到了广泛的应用 [@Virgilio2018;@Blangiardo2015;@Faraway2018]。


## 空间广义线性混合效应模型 {#sim-sglmm}

### 响应变量服从二项分布 {#sim-binomal-sglmm}

响应变量服从二项分布 $Y_{i} \sim \mathrm{Binomal}(m_{i},p(x_{i}))$，在位置 $x_i$ 处，以概率 $p(x_i)$ 重复抽取了 $m_i$ 个样本，总样本数 $M=\sum_{i=1}^{N}m_i$，$N$ 是采样点的个数，二项空间广义线性混合效应模型为 \@ref(eq:binom-SGLMM)，联系函数为 $g(\mu_i) = \log\{\frac{p(x_i)}{1-p(x_i)}\}$，$S(x)$ 是均值为 $\mathbf{0}$，协方差函数为 $\mathrm{Cov}(S(x_i),S(x_j)) = \sigma^2 \big\{2^{\kappa-1}\Gamma(\kappa)\big\}^{-1}(u/\phi)^{\kappa}K_{\kappa}(u/\phi), \kappa = 0.5$ 的平稳空间高斯过程。

\begin{equation}
g(\mu_i) = \log\{\frac{p(x_i)}{1-p(x_i)}\} = \alpha + S(x_i) (\#eq:binom-SGLMM)
\end{equation}

固定效应参数 $\alpha = 0$，协方差参数记为 $\boldsymbol{\theta} = (\sigma^2, \phi) = (0.5, 0.2)$，采样点数目为 $N = 64$，每个采样点抽取的样本数 $m_i = 4, i = 1, 2, \ldots, 64$。首先模拟平稳空间高斯过程 $S(x)$，在单位区域 $[0,1] \times [0,1]$ 划分为 $8 \times 8$ 的网格，格点选为采样位置，用 **geoR** 包提供的 `grf` 函数产生协方差参数为 $\boldsymbol{\theta} = (\sigma^2,\phi) = (0.5, 0.2)$ 的平稳空间高斯过程，由公式 \@ref(eq:binom-SGLMM) 可知 $p(x_i) = \exp(S(x_i))/(1 + \exp(S(x_i)))$， 即每个格点处二项分布的概率值，然后依此概率，由 `rbinom` 函数产生服从二项分布的观察值 $Y_i$，$Y_i$ 的取值范围为 $0, 1, 2, 3, 4$，模拟的数据集可以用图 \@ref(fig:binom-without-nugget-geoRglm) 直观表示。

```{r binom-without-nugget-geoRglm,fig.cap="左图表示二维规则平面上的平稳空间高斯过程，格点是采样点的位置，其上的数字是 $p(x)$ 的值，已经四舍五入保留两位小数，右图表示观察值 $Y$ 随空间位置的变化，格点上的值即为观察值 $Y$，图中的两个圈分别是第1个(左下)和第29个(右上)采样点",out.width="90%"}
knitr::include_graphics(path = "figures/binom-without-nugget-geoRglm.png")
```

基于 Langevin-Hastings 采样器实现的马尔科夫链蒙特卡罗算法，参数 $\alpha$ 的先验分布选均值为 0，方差为 1 的标准正态分布，参数 $\phi$ 的先验分布选期望为 0.2 的指数分布，参数 $\sigma^2$ 的先验分布是非中心的逆卡方分布，其非中心化参数为 0.5，自由度为 5，各参数的先验选择来自 Ole F. Christensen 和 Peter J. Ribeiro Jr. (2002年) [@geoRglm2002]。Langevin-Hastings 算法运行 110000 次迭代，前 10000 次迭代用作热身 (warm-up)，后 10 万次迭代里间隔 100 次迭代采样，获得关于参数 $\alpha,\phi,\sigma^2$ 的后验分布的样本，样本量是1000。

\begin{align}
\alpha   & \sim \mathcal{N}(0,1) \\
\phi     & \sim \mathrm{Exp}(0.2) \\
\sigma^2 & \sim \mathrm{Inv-}\chi^2(5,0.5)
\end{align}

Table: (\#tab:MCLH-vs-NUTS)  Langevin-Hastings 算法与汉密尔顿蒙特卡罗算法的数值模拟比较，模型参数 $\alpha,\phi,\sigma^2$ 的估计值（后验分布的均值）、方差（后验分布的方差）和 5 个分位点（后验分布的 5 个分位点），采样点数目分别考虑了 $N = 36, 64, 81, 100$ 的情况，括号内为相应参数的真值

|        |  true|  mean|   var|   2.5\%|    25\%|   50\%|   75\%| 97.5\%|   N  |
|:-------|-----:|-----:|-------:|-------:|------:|------:|------:|-----:|-----:|
|$\alpha$    |   0.0| -0.354|  0.079|  -0.938|  -0.524| -0.361| -0.173|  0.215| 36 |
|$\phi$      |   0.2|  0.121|  0.006|   0.005|   0.055|  0.110|  0.180|  0.285| 36 |
|$\sigma^2$  |   0.5|  0.683|  0.147|   0.215|   0.408|  0.596|  0.850|  1.667| 36 |
|$\alpha$    |   0.0|  0.003|  0.089|  -0.596|  -0.169|  0.013|  0.179|  0.609| 64 |
|$\phi$      |   0.2|  0.194|  0.004|   0.070|   0.145|  0.195|  0.250|  0.295| 64 |
|$\sigma^2$  |   0.5|  0.656|  0.096|   0.254|   0.449|  0.592|  0.781|  1.453| 64 |
|$\beta$     |   0.0| -0.155|  0.044|  -0.565|  -0.284| -0.156|  -0.03|  0.273| 81 |
|$\phi$      |   0.2|  0.116|  0.006|   0.005|   0.055|  0.105|   0.17|  0.280| 81 |
|$\sigma^2$  |   0.5|  0.468|  0.057|   0.180|   0.311|  0.414|   0.56|  1.129| 81 |
|$\alpha$    |   0.0|  -0.230|  0.209|  -1.127|  -0.521|  -0.214|  0.056|  0.653|  36|
|$\phi$      |   0.2|   1.103|  0.364|   0.459|   0.721|   0.936|  1.284|  2.669|  36|
|$\sigma^2$  |   0.5|   0.474|  0.187|   0.105|   0.216|   0.333|  0.573|  1.572|  36|
|$\alpha$    |   0.0|  0.046|  0.251|  -0.947|  -0.269|  0.049|  0.356|  1.069|  64|
|$\phi$      |   0.2|  1.042|  0.246|   0.471|   0.708|  0.921|  1.247|  2.324|  64|
|$\sigma^2$  |   0.5|  0.647|  0.228|   0.170|   0.338|  0.524|  0.779|  1.958|  64|
|$\alpha$    |   0.0|  -0.082|  0.170|  -0.893|  -0.321|  -0.078|  0.174|  0.742|  81|
|$\phi$      |   0.2|   1.110|  0.331|   0.453|   0.721|   0.986|  1.330|  2.506|  81|
|$\sigma^2$  |   0.5|   0.410|  0.105|   0.105|   0.205|   0.317|  0.503|  1.211|  81|

参数 $\alpha,\phi,\sigma^2$ 的贝叶斯估计没有显式表达式，通常用后验分布的均值作为参数的估计，即所谓的贝叶斯估计，它的定义就是使得估计的均方误差达到最小时的估计。贝叶斯估计 的精度或者说好坏常用后验分布的方差衡量，因为均方误差在参数估计取后验均值时就是后验方差，所以表 \@ref(tab:MCLH-vs-NUTS) 不再提供估计的均方误差值，而是提供了 5 个后验分布的分位点，在 95\% 的置信水平下，样本分位点 0.025 和 0.975 的值组成了置信区间的上下界。除了获得各参数的估计值外，还获得 64 个采样点处 $p(x_i), i = 1, \ldots, 64$ 的后验均值、方差、标准差和 5个分位点，详见附表 \@ref(tab:LH-binom-SGLMM)


### 响应变量服从泊松分布 {#possion-sglmm}

响应变量 $Y$ 服从泊松分布，即 $Y_i \sim \mathrm{Possion}(\lambda(x_{i}))$，泊松空间广义线性混合效应模型 \@ref(eq:pois-SGLMM)

\begin{equation}
g(\mu_i) = \log(\lambda(x_i)) = \alpha + S(x_i) (\#eq:pois-SGLMM)
\end{equation}

\noindent 其中，$S(x)$ 是平稳空间高斯过程，其均值为 $\mathbf{0}$，协方差函数为 $\mathrm{Cov}(S(x_i),S(x_j)) = \sigma^2 \big\{2^{\kappa-1}\Gamma(\kappa)\big\}^{-1}(u/\phi)^{\kappa}K_{\kappa}(u/\phi)$，联系函数 $g(\mu_i) = \log\{\lambda(x_{i})\}$。

类似 \@ref(sim-binomal-sglmm) 小节，首先产生服从平稳空间高斯过程 $S(x)$ 的随机数 $S(x_i),i=1,\ldots,N$，然后根据 \@ref(eq:pois-SGLMM) 式， $\lambda(x_i) = \exp(\alpha + S(x_i))$，又响应变量 $Y_i \sim \mathrm{Possion}(\lambda(x_{i}))$，根据 R 内置函数 `rpois` 产生服从参数为 $\lambda(x_i)$ 的泊松分布的随机数。

Table: (\#tab:Pois-MCLV-vs-NUTS) 模型参数真值设置为 $\alpha = 0.5, \phi = 0.2, \sigma^2 = 2.0, \kappa = 1.5$，采样点数目分别为 $N=36,64,100$

|           |  true|   mean|    var|    2.5%|     25%|    50%|    75%|  97.5%|   N   |
|:----------|-----:|------:|------:|-------:|-------:|------:|------:|------:|------:|
|$\alpha$   |   0.5|  0.527|  0.418|  -0.759|   0.189|  0.514|  0.855|  1.864|  36|
|$\phi$     |   0.2|  0.401|  0.052|   0.100|   0.240|  0.360|  0.520|  0.960|  36|
|$\sigma^2$ |   2.0|  1.311|  0.660|   0.365|   0.766|  1.081|  1.584|  3.562|  36|
|$\alpha$   |   0.5|  0.866|  1.517|  -1.610|   0.059|  0.870|  1.666|  3.159|  64|
|$\phi$     |   0.2|  0.682|  0.073|   0.300|   0.480|  0.640|  0.820|  1.380|  64|
|$\sigma^2$ |   2.0|  3.932|  2.594|   1.667|   2.800|  3.642|  4.744|  7.740|  64|
|$\alpha$   |   0.5|  0.323|  0.657|  -1.449|  -0.124|  0.416|  0.812|  1.831|  100 |
|$\phi$     |   0.2|  0.617|  0.085|   0.220|   0.400|  0.560|  0.785|  1.320|  100 |
|$\sigma^2$ |   2.0|  1.479|  0.498|   0.545|   0.941|  1.352|  1.822|  3.195|  100 |
|$\alpha$   |   0.5|  0.483|  0.310|  -0.608|   0.094|  0.488|  0.851|  1.613|  36|
|$\phi$     |   0.2|  0.631|  0.036|   0.362|   0.501|  0.602|  0.722|  1.090|  36|
|$\sigma^2$ |   2.0|  1.370|  0.298|   0.455|   0.977|  1.317|  1.714|  2.566|  36|
|$\alpha$   |   0.5|  0.498|  0.402|  -0.775|   0.082|  0.534|  0.917|  1.798|  64|
|$\phi$     |   0.2|  0.385|  0.003|   0.285|   0.343|  0.380|  0.422|  0.509|  64|
|$\sigma^2$ |   2.0|  2.473|  0.292|   1.585|   2.102|  2.416|  2.804|  3.734|  64|
|$\alpha$   |   0.5|  0.160|  0.317|  -0.999|  -0.213|  0.189|  0.548|  1.181|  100|
|$\phi$     |   0.2|  0.461|  0.006|   0.331|   0.406|  0.455|  0.511|  0.628|  100|
|$\sigma^2$ |   2.0|  1.848|  0.317|   0.889|   1.441|  1.779|  2.173|  3.124|  100|

100 个采样点的模拟实验中，精心调了 Langevin-Hastings 算法的参数，得到比较好的估计值，在该组参数设置下，更改采样点数目分别为 36 和 64，得到估计值，见表 \@ref(tab:Pois-MCLV-vs-NUTS)，可以看出估计值变差。

添加偏差、置信区间长度、时间花费

Stan 2000 次迭代，前 1000 次迭代作为 warm-up 阶段，后 1000 次迭代全部采样，所以样本量也是1000。

完整的表格见附表 \@ref(tab:HMC-Pois-SGLMM)

## 本章小结 {#sec:simulations}
